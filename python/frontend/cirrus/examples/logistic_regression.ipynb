{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "---\n",
    "This notebook uses Cirrus to run logistic regression on the Criteo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ease development, each time a cell is run, all modules will be reloaded.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import atexit\n",
    "import time\n",
    "\n",
    "from test import *\n",
    "from cirrus import instance, automate, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cirrus produces logs, but they will not show unless we add a handler that prints.\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter(\"[%(funcName)16s | %(threadName)15s] %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger = logging.getLogger(\"cirrus\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance, server, and task\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start an EC2 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        __init__ |      MainThread] __init__: Resolving AMI owner/name to AMI ID.\n",
      "[    ec2_resource |      MainThread] ClientManager: Initializing EC2 resource.\n",
      "[          config |      MainThread] config: Configuration loaded.\n",
      "[        __init__ |      MainThread] __init__: Done.\n",
      "[         _exists |      MainThread] _exists: Listing instances.\n",
      "[         _exists |      MainThread] _exists: No existing instance with the same name was found.\n",
      "[ _start_and_wait |      MainThread] _start_and_wait: Starting a new instance.\n",
      "[ _start_and_wait |      MainThread] _start_and_wait: Waiting for instance to enter running state.\n",
      "[ _start_and_wait |      MainThread] _start_and_wait: Fetching instance metadata.\n",
      "[ _start_and_wait |      MainThread] _start_and_wait: Done.\n",
      "[           start |      MainThread] start: Done.\n"
     ]
    }
   ],
   "source": [
    "inst = instance.Instance(\n",
    "    name=\"lr_example_instance\",\n",
    "    disk_size=32,\n",
    "    typ=\"m5a.2xlarge\",\n",
    "    username=\"ubuntu\",\n",
    "    ami_owner_name=(\"self\", \"cirrus_server_image\")\n",
    ")\n",
    "inst.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we create a parameter server to run on our instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = automate.ParameterServer(\n",
    "    instance=inst,\n",
    "    ps_port=1337,\n",
    "    error_port=1338,\n",
    "    num_workers=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we define our machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = lr.LogisticRegression(\n",
    "    n_workers=16,\n",
    "    n_ps=1,\n",
    "    dataset=\"criteo-kaggle-19b\",\n",
    "    learning_rate=0.0001,\n",
    "    epsilon=0.0001,\n",
    "    progress_callback=None,\n",
    "    train_set=(0, 799),\n",
    "    test_set=(800, 915),\n",
    "    minibatch_size=200,\n",
    "    model_bits=19,\n",
    "    ps=server,\n",
    "    opt_method=\"adagrad\",\n",
    "    timeout=60,\n",
    "    lambda_size=192\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run our machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[           start |      MainThread] start: Uploading configuration.\n",
      "[     run_command |      MainThread] run_command: Calling _connect_ssh.\n",
      "[    _connect_ssh |      MainThread] _connect_ssh: Configuring.\n",
      "[    _connect_ssh |      MainThread] _connect_ssh: Making connection attempt #1 out of 20.\n",
      "[    _connect_ssh |      MainThread] _connect_ssh: Connection attempt timed out after 5s.\n",
      "[    _connect_ssh |      MainThread] _connect_ssh: Making connection attempt #2 out of 20.\n",
      "[    _connect_ssh |      MainThread] _connect_ssh: Connection attempt failed. Sleeping for 5s.\n",
      "[    _connect_ssh |      MainThread] _connect_ssh: Making connection attempt #3 out of 20.\n",
      "[     run_command |      MainThread] run_command: Running `echo 'load_input_path: /mnt/efs/criteo_kaggle/train.csv \n",
      "load_input_type: csv\n",
      "dataset_format: binary\n",
      "num_classes: 2 \n",
      "num_features: 13 \n",
      "limit_cols: 14 \n",
      "normalize: 0 \n",
      "limit_samples: 10000 \n",
      "s3_size: 50000 \n",
      "use_bias: 1 \n",
      "model_type: LogisticRegression \n",
      "minibatch_size: 200 \n",
      "learning_rate: 0.000100 \n",
      "epsilon: 0.000100 \n",
      "model_bits: 19 \n",
      "s3_bucket: criteo-kaggle-19b \n",
      "use_grad_threshold: 0 \n",
      "grad_threshold: 0.001000 \n",
      "train_set: 0-799 \n",
      "test_set: 800-915' > config_1337.txt`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 0.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "[           start |      MainThread] start: Starting parameter server.\n",
      "[     run_command |      MainThread] run_command: Running `ulimit -c unlimited; nohup ./parameter_server --config config_1337.txt --nworkers 64 --rank 1 --ps_port 1337 &> ps_out_1337 &`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 0.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "[           start |      MainThread] start: Retreiving parameter server PID.\n",
      "[     run_command |      MainThread] run_command: Running `echo $! > ps_1337.pid`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 0.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "[           start |      MainThread] start: Starting error task.\n",
      "[     run_command |      MainThread] run_command: Running `ulimit -c unlimited; nohup ./parameter_server --config config_1337.txt --nworkers 64 --rank 2 --ps_ip 172.31.44.210 --ps_port 1337 &> error_out_1337 &`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 0.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "[           start |      MainThread] start: Retreiving error task PID.\n",
      "[     run_command |      MainThread] run_command: Running `echo $! > error_1337.pid`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 0.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "[wait_until_started |        Thread-9] start: Making connection attempt #1 to ParameterServer@54.202.39.131:1337.\n",
      "[wait_until_started |        Thread-9] start: ParameterServer@54.202.39.131:1337 launched.\n",
      "[     make_lambda |        Thread-9] make_lambda: Deleting any existing Lambda.\n",
      "[            lamb |        Thread-9] ClientManager: Initializing Lambda client.\n",
      "[     make_lambda |        Thread-9] make_lambda: Copying package to user's bucket.\n",
      "[ get_bucket_name |        Thread-9] get_bucket_name: Retreiving account ID.\n",
      "[             sts |        Thread-9] ClientManager: Initializing STS client.\n",
      "[              s3 |        Thread-9] ClientManager: Initializing S3 resource.\n",
      "[     make_lambda |        Thread-9] make_lambda: Creating Lambda.\n",
      "[             iam |        Thread-9] ClientManager: Initializing IAM resource.\n",
      "[     make_lambda |        Thread-9] make_lambda: Allocating reserved concurrent executions to the Lambda.\n",
      "[     make_lambda |        Thread-9] make_lambda: Done.\n",
      "[           new_f | Exp #00 Wkr #00] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #01] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #02] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #03] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #04] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #05] jittery_exponential_backoff: Making attempt #1.\n",
      "[   launch_worker | Exp #00 Wkr #00] launch_worker: Launching Task 0.\n",
      "[           new_f | Exp #00 Wkr #06] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #07] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #08] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #09] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #10] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #11] jittery_exponential_backoff: Making attempt #1.\n",
      "[   launch_worker | Exp #00 Wkr #01] launch_worker: Launching Task 10000.\n",
      "[           new_f | Exp #00 Wkr #12] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #13] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #14] jittery_exponential_backoff: Making attempt #1.\n",
      "[           new_f | Exp #00 Wkr #15] jittery_exponential_backoff: Making attempt #1.\n",
      "[   launch_worker | Exp #00 Wkr #02] launch_worker: Launching Task 20000.\n",
      "[   launch_worker | Exp #00 Wkr #03] launch_worker: Launching Task 30000.\n",
      "[   launch_worker | Exp #00 Wkr #04] launch_worker: Launching Task 40000.\n",
      "[   launch_worker | Exp #00 Wkr #05] launch_worker: Launching Task 50000.\n",
      "[ lamb_no_retries | Exp #00 Wkr #00] ClientManager: Initializing no-retries Lambda client.\n",
      "[   launch_worker | Exp #00 Wkr #06] launch_worker: Launching Task 60000.\n",
      "[   launch_worker | Exp #00 Wkr #07] launch_worker: Launching Task 70000.\n",
      "[   launch_worker | Exp #00 Wkr #08] launch_worker: Launching Task 80000.\n",
      "[   launch_worker | Exp #00 Wkr #09] launch_worker: Launching Task 90000.\n",
      "[   launch_worker | Exp #00 Wkr #10] launch_worker: Launching Task 100000.\n",
      "[   launch_worker | Exp #00 Wkr #11] launch_worker: Launching Task 110000.\n",
      "[   launch_worker | Exp #00 Wkr #12] launch_worker: Launching Task 120000.\n",
      "[   launch_worker | Exp #00 Wkr #13] launch_worker: Launching Task 130000.\n",
      "[   launch_worker | Exp #00 Wkr #14] launch_worker: Launching Task 140000.\n",
      "[   launch_worker | Exp #00 Wkr #15] launch_worker: Launching Task 150000.\n"
     ]
    }
   ],
   "source": [
    "task.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to see the present accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     run_command |      MainThread] run_command: Running `cat error_out_1337`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 24017.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "[ERROR_TASK] computing loss.\n",
      "[ERROR_TASK] Loss (Total/Avg): 3.82638e+06/0.665457 Accuracy: 0.745537 time(us): 1544048106102798 time from start (sec): 18.1391\n",
      "[ERROR_TASK] getting the full model\n",
      "[ERROR_TASK] received the model\n",
      "[ERROR_TASK] computing loss.\n",
      "[ERROR_TASK] Loss (Total/Avg): 3.81651e+06/0.663741 Accuracy: 0.745579 time(us): 1544048110753799 time from start (sec): 22.7901\n",
      "[ERROR_TASK] getting the full model\n",
      "[ERROR_TASK] received the model\n",
      "[ERROR_TASK] computing loss.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in server.error_output().split(\"\\n\")[-10:]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     run_command |      MainThread] run_command: Running `cat error_out_1337`.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 72298.\n",
      "[     run_command |      MainThread] run_command: stderr had length 0.\n",
      "[     run_command |      MainThread] run_command: Exit code was 0.\n",
      "[     run_command |      MainThread] run_command: Done.\n",
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "test(server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're satisfied with the results, we kill our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     run_command |      MainThread] run_command: Running `kill -n 9 $(cat error_1337.pid)`.\n",
      "[   delete_lambda | Exp #00 Cleanup] delete_lambda: Deleting Lambda function cirrus_worker_0_2018-12-5_14-14-19-582000.\n",
      "[     run_command |      MainThread] run_command: Waiting for completion.\n",
      "[     run_command |      MainThread] run_command: Fetching stdout and stderr.\n",
      "[     run_command |      MainThread] run_command: stdout had length 0.\n",
      "[     run_command |      MainThread] run_command: stderr had length 93.\n",
      "[     run_command |      MainThread] run_command: Exit code was 2.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`kill -n 9 $(cat error_1337.pid)` returned nonzero exit code 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-eaa7fe2dc53f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ryan\\documents\\cirrus-1\\python\\frontend\\cirrus\\cirrus\\core.pyc\u001b[0m in \u001b[0;36mkill\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m#   parameter server, we ensure that all workers are killed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;31m# Any currently-running Lambdas will probably die during this wait. As a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\documents\\cirrus-1\\python\\frontend\\cirrus\\cirrus\\automate.pyc\u001b[0m in \u001b[0;36mstop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ps\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mkill_command\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"kill -n 9 $(cat %s_%d.pid)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mps_port\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkill_command\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;31m# TODO: Here we should probably wait for the process to die and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;31m#   raise an error if it doesn't in a certain amount of time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\documents\\cirrus-1\\python\\frontend\\cirrus\\cirrus\\instance.pyc\u001b[0m in \u001b[0;36mrun_command\u001b[1;34m(self, command, check)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             raise RuntimeError(\"`%s` returned nonzero exit code %d.\"\n\u001b[1;32m--> 439\u001b[1;33m                                % (command, status))\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"run_command: Done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: `kill -n 9 $(cat error_1337.pid)` returned nonzero exit code 2."
     ]
    }
   ],
   "source": [
    "task.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to terminate our instance in order to avoid continuing charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[         cleanup |      MainThread] cleanup: Closing SSH client.\n",
      "[         cleanup |      MainThread] cleanup: Terminating instance.\n",
      "[         cleanup |      MainThread] cleanup: Waiting for instance to terminate.\n",
      "[   launch_worker | Exp #00 Wkr #05] launch_worker: Task 50003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #10] launch_worker: Task 100003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #06] launch_worker: Task 60003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #03] launch_worker: Task 30003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #11] launch_worker: Task 110003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #13] launch_worker: Task 130003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #04] launch_worker: Task 40003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #14] launch_worker: Task 140003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #00] launch_worker: Task 3 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #02] launch_worker: Task 20003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #07] launch_worker: Task 70003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #09] launch_worker: Task 90003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #08] launch_worker: Task 80003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #15] launch_worker: Task 150003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #01] launch_worker: Task 10003 completed with status code 200.\n",
      "[   launch_worker | Exp #00 Wkr #12] launch_worker: Task 120003 completed with status code 200.\n",
      "[         cleanup |      MainThread] cleanup: Done.\n"
     ]
    }
   ],
   "source": [
    "inst.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
