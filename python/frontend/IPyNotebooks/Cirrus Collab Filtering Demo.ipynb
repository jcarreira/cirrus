{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cirrus Demo\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "This will run a simple logistic regression on the Criteo Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 (default, Dec  4 2017, 14:50:18) \n",
      "[GCC 5.4.0 20160609]\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import collab\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "print __version__ # requires version >= 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~andrewmzhang/11.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "import plotly.plotly as py  \n",
    "import plotly.tools as tls   \n",
    "import plotly.graph_objs as go\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "stream_ids = tls.get_credentials_file()['stream_ids']\n",
    "\n",
    "# Get stream id from stream id list \n",
    "stream_id = stream_ids[0]\n",
    "\n",
    "\n",
    "py.iplot([{'x': [], 'y': [], 'type': 'scatter', 'mode': 'lines+markers',\n",
    "            'stream': {'token': stream_id, 'maxpoints': 80}\n",
    "          }],\n",
    "        filename='Time Series', fileopt='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We will provide the stream link object the same token that's associated with the trace we wish to stream to\n",
    "s = py.Stream(stream_id)\n",
    "\n",
    "# We then open a connection\n",
    "s.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_callback(time_loss, cost, task):\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    s.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running collaborative filtering workload\n",
      "Starting CollaborativeFilteringTask\n",
      "User's specific ip: ec2-34-219-23-178.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm\n",
      "Done waiting... Attempting to copy over binary\n",
      "Copied parameter server\n",
      "Defining configuration file\n",
      "\n",
      "input_path: /home/ec2-user/cirrus/examples/ml/tests/test_mf/nf_parsed \n",
      "input_type: csv \n",
      "minibatch_size: 20 \n",
      "s3_size: 10000 \n",
      "model_type: CollaborativeFiltering \n",
      "learning_rate: 0.010000 \n",
      "epsilon: 0.000100 \n",
      "normalize: 1 \n",
      "limit_samples: 50000000 \n",
      "use_bias: 1 \n",
      "num_users: 480189 \n",
      "num_items: 17770 \n",
      "train_set: 0-5 \n",
      "s3_bucket: cirrus-netflix-not-normalized\n",
      "\n",
      "Launching ps\n",
      "Launching parameter server\n",
      "('cmd:', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ec2-user@ec2-34-219-23-178.us-west-2.compute.amazonaws.com \"nohup ./parameter_server config_cf.txt 10000 1 &> ps_output &\"')\n",
      "Launching lambdas\n",
      "launching lambda with id 3\n",
      "launching lambda with id 4\n",
      "('cmd', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ec2-user@ec2-34-219-23-178.us-west-2.compute.amazonaws.com \"./parameter_server config_cf.txt 10 2\" > error_out &')\n",
      "relaunching lambda with id 4 1\n",
      "[ERROR_TASK] RMSE (Total): 1.08849 time(us): 1529043213959101 time from start (sec): 5.82841\n",
      "\n",
      "('Current training loss:', (5.8284, 1.08849), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.03963 time(us): 1529043218583046 time from start (sec): 10.4524\n",
      "\n",
      "('Current training loss:', (10.452, 1.03963), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.0297 time(us): 1529043223246511 time from start (sec): 15.1158\n",
      "\n",
      "('Current training loss:', (15.115, 1.0297), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.02304 time(us): 1529043227485816 time from start (sec): 19.3551\n",
      "\n",
      "('Current training loss:', (19.355, 1.02304), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.01907 time(us): 1529043231731096 time from start (sec): 23.6004\n",
      "\n",
      "('Current training loss:', (23.6, 1.01907), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.01635 time(us): 1529043236085542 time from start (sec): 27.9548\n",
      "\n",
      "('Current training loss:', (27.954, 1.01635), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.01184 time(us): 1529043241733597 time from start (sec): 33.6029\n",
      "\n",
      "('Current training loss:', (33.602, 1.01184), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.0065 time(us): 1529043246401767 time from start (sec): 38.2711\n",
      "\n",
      "('Current training loss:', (38.271, 1.0065), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.00366 time(us): 1529043250742969 time from start (sec): 42.6123\n",
      "\n",
      "('Current training loss:', (42.612, 1.00366), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.0029 time(us): 1529043255491397 time from start (sec): 47.3607\n",
      "\n",
      "('Current training loss:', (47.36, 1.0029), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.00267 time(us): 1529043260019992 time from start (sec): 51.8893\n",
      "\n",
      "('Current training loss:', (51.889, 1.00267), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.00156 time(us): 1529043264427793 time from start (sec): 56.2971\n",
      "\n",
      "('Current training loss:', (56.297, 1.00156), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.00317 time(us): 1529043268364233 time from start (sec): 60.2335\n",
      "\n",
      "('Current training loss:', (60.233, 1.00317), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.00365 time(us): 1529043273265634 time from start (sec): 65.1349\n",
      "\n",
      "('Current training loss:', (65.134, 1.00365), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 1.00249 time(us): 1529043279489764 time from start (sec): 71.3591\n",
      "\n",
      "('Current training loss:', (71.359, 1.00249), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 0.999427 time(us): 1529043285219898 time from start (sec): 77.0892\n",
      "\n",
      "('Current training loss:', (77.089, 0.999427), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 0.998062 time(us): 1529043290667766 time from start (sec): 82.5371\n",
      "\n",
      "('Current training loss:', (82.537, 0.998062), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 0.996478 time(us): 1529043295978641 time from start (sec): 87.8479\n",
      "\n",
      "('Current training loss:', (87.847, 0.996478), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 0.993516 time(us): 1529043301946559 time from start (sec): 93.8159\n",
      "\n",
      "('Current training loss:', (93.815, 0.993516), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 0.991993 time(us): 1529043307708351 time from start (sec): 99.5777\n",
      "\n",
      "('Current training loss:', (99.577, 0.991993), 'current cost ($): ', 0.1)\n",
      "[ERROR_TASK] RMSE (Total): 0.986147 time(us): 1529043312727070 time from start (sec): 104.596\n",
      "\n",
      "('Current training loss:', (104.59, 0.986147), 'current cost ($): ', 0.1)\n",
      "error is timing out\n",
      "Waiting for threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"collab.py\", line 117, in launch\n",
      "    Payload='{\"num_task\": %d, \"num_workers\": %d}' % (num_task, num_workers))\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/client.py\", line 314, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/client.py\", line 599, in _make_api_call\n",
      "    operation_model, request_dict)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/endpoint.py\", line 148, in make_request\n",
      "    return self._send_request(request_dict, operation_model)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/endpoint.py\", line 177, in _send_request\n",
      "    success_response, exception):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/endpoint.py\", line 273, in _needs_retry\n",
      "    caught_exception=caught_exception, request_dict=request_dict)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/hooks.py\", line 227, in emit\n",
      "    return self._emit(event_name, kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/hooks.py\", line 210, in _emit\n",
      "    response = handler(**kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 183, in __call__\n",
      "    if self._checker(attempts, response, caught_exception):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 251, in __call__\n",
      "    caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 277, in _should_retry\n",
      "    return self._checker(attempt_number, response, caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 317, in __call__\n",
      "    caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 223, in __call__\n",
      "    attempt_number, caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 359, in _check_caught_exception\n",
      "    raise caught_exception\n",
      "ReadTimeout: HTTPSConnectionPool(host='lambda.us-west-2.amazonaws.com', port=443): Read timed out. (read timeout=60)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas have been launched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"collab.py\", line 117, in launch\n",
      "    Payload='{\"num_task\": %d, \"num_workers\": %d}' % (num_task, num_workers))\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/client.py\", line 314, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/client.py\", line 599, in _make_api_call\n",
      "    operation_model, request_dict)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/endpoint.py\", line 148, in make_request\n",
      "    return self._send_request(request_dict, operation_model)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/endpoint.py\", line 177, in _send_request\n",
      "    success_response, exception):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/endpoint.py\", line 273, in _needs_retry\n",
      "    caught_exception=caught_exception, request_dict=request_dict)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/hooks.py\", line 227, in emit\n",
      "    return self._emit(event_name, kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/hooks.py\", line 210, in _emit\n",
      "    response = handler(**kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 183, in __call__\n",
      "    if self._checker(attempts, response, caught_exception):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 251, in __call__\n",
      "    caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 277, in _should_retry\n",
      "    return self._checker(attempt_number, response, caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 317, in __call__\n",
      "    caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 223, in __call__\n",
      "    attempt_number, caught_exception)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/botocore/retryhandler.py\", line 359, in _check_caught_exception\n",
      "    raise caught_exception\n",
      "ReadTimeout: HTTPSConnectionPool(host='lambda.us-west-2.amazonaws.com', port=443): Read timed out. (read timeout=60)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_bucket = 'cirrus-criteo-kaggle-19b-random'\n",
    "model = 'model_v1'\n",
    "\n",
    "lr_task = collab.CollaborativeFiltering(\n",
    "             # number of workers and number of PSs\n",
    "             n_workers = 3, n_ps = 2,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01, epsilon=0.0001,\n",
    "             #\n",
    "             progress_callback = progress_callback,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip='ec2-34-219-23-178.us-west-2.compute.amazonaws.com',\n",
    "             # username of VM\n",
    "             ps_username='ec2-user',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=True,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(825,827)\n",
    "             )\n",
    "\n",
    "lr_task.run()\n",
    "\n",
    "#model, loss = lr_task.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
