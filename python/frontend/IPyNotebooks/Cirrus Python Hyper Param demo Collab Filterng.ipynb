{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cirrus Demo\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "This will run a simple logistic regression on the Criteo Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 (default, Dec  4 2017, 14:50:18) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.genUID = function() {\n",
       "    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n",
       "        var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n",
       "        return v.toString(16);\n",
       "    });\n",
       "};\n",
       "\n",
       "\n",
       "define('graphWidget', [\"@jupyter-widgets/base\"], function (widget) {\n",
       "\n",
       "    var GraphView = widget.DOMWidgetView.extend({\n",
       "        render: function(){\n",
       "            var that = this;\n",
       "\n",
       "            var graphId = window.genUID();\n",
       "            var loadingId = 'loading-'+graphId;\n",
       "\n",
       "\n",
       "            var _graph_url = that.model.get('_graph_url');\n",
       "\n",
       "            // variable plotlyDomain in the case of enterprise\n",
       "            var url_parts = _graph_url.split('/');\n",
       "            var plotlyDomain = url_parts[0] + '//' + url_parts[2];\n",
       "\n",
       "            if(!('plotlyDomains' in window)){\n",
       "                window.plotlyDomains = {};\n",
       "            }\n",
       "            window.plotlyDomains[graphId] = plotlyDomain;\n",
       "\n",
       "            // Place IFrame in output cell div `$el`\n",
       "            that.$el.css('width', '100%');\n",
       "            that.$graph = $(['<iframe id=\"'+graphId+'\"',\n",
       "                             'src=\"'+_graph_url+'.embed\"',\n",
       "                             'seamless',\n",
       "                             'style=\"border: none;\"',\n",
       "                             'width=\"100%\"',\n",
       "                             'height=\"600\">',\n",
       "                             '</iframe>'].join(' '));\n",
       "            that.$graph.appendTo(that.$el);\n",
       "\n",
       "            that.$loading = $('<div id=\"'+loadingId+'\">Initializing...</div>')\n",
       "                            .appendTo(that.$el);\n",
       "\n",
       "            // for some reason the 'width' is being changed in IPython 3.0.0\n",
       "            // for the containing `div` element. There's a flicker here, but\n",
       "            // I was unable to fix it otherwise.\n",
       "            setTimeout(function ()  {\n",
       "                if (IPYTHON_VERSION === '3') {\n",
       "                    $('#' + graphId)[0].parentElement.style.width = '100%';\n",
       "                }\n",
       "            }, 500);\n",
       "\n",
       "            // initialize communication with the iframe\n",
       "            if(!('pingers' in window)){\n",
       "                window.pingers = {};\n",
       "            }\n",
       "\n",
       "            window.pingers[graphId] = setInterval(function() {\n",
       "                that.graphContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                that.graphContentWindow.postMessage({task: 'ping'}, plotlyDomain);\n",
       "            }, 200);\n",
       "\n",
       "            // Assign a message listener to the 'message' events\n",
       "            // from iframe's postMessage protocol.\n",
       "            // Filter the messages by iframe src so that the right message\n",
       "            // gets passed to the right widget\n",
       "            if(!('messageListeners' in window)){\n",
       "                 window.messageListeners = {};\n",
       "            }\n",
       "\n",
       "            window.messageListeners[graphId] = function(e) {\n",
       "                if(_graph_url.indexOf(e.origin)>-1) {\n",
       "                    var frame = document.getElementById(graphId);\n",
       "\n",
       "                    if(frame === null){\n",
       "                        // frame doesn't exist in the dom anymore, clean up it's old event listener\n",
       "                        window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "                        clearInterval(window.pingers[graphId]);\n",
       "                    } else if(frame.contentWindow === e.source) {\n",
       "                        // TODO: Stop event propagation, so each frame doesn't listen and filter\n",
       "                        var frameContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                        var message = e.data;\n",
       "\n",
       "                        if('pong' in message && message.pong) {\n",
       "                            $('#loading-'+graphId).hide();\n",
       "                            clearInterval(window.pingers[graphId]);\n",
       "                            that.send({event: 'pong', graphId: graphId});\n",
       "                        } else if (message.type==='hover' ||\n",
       "                                   message.type==='zoom'  ||\n",
       "                                   message.type==='click' ||\n",
       "                                   message.type==='unhover') {\n",
       "\n",
       "                            // click and hover events contain all of the data in the traces,\n",
       "                            // which can be a very large object and may take a ton of time\n",
       "                            // to pass to the python backend. Strip out the data, and require\n",
       "                            // the user to call get_figure if they need trace information\n",
       "                            if(message.type !== 'zoom') {\n",
       "                                for(var i in message.points) {\n",
       "                                    delete message.points[i].data;\n",
       "                                    delete message.points[i].fullData;\n",
       "                                }\n",
       "                            }\n",
       "                            that.send({event: message.type, message: message, graphId: graphId});\n",
       "                        } else if (message.task === 'getAttributes') {\n",
       "                            that.send({event: 'getAttributes', response: message.response});\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            };\n",
       "\n",
       "            window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "            window.addEventListener('message', window.messageListeners[graphId]);\n",
       "\n",
       "        },\n",
       "\n",
       "        update: function() {\n",
       "            // Listen for messages from the graph widget in python\n",
       "            var jmessage = this.model.get('_message');\n",
       "            var message = JSON.parse(jmessage);\n",
       "\n",
       "            // check for duplicate messages\n",
       "            if(!('messageIds' in window)){\n",
       "                window.messageIds = {};\n",
       "            }\n",
       "\n",
       "            if(!(message.uid in window.messageIds)){\n",
       "                // message hasn't been received yet, do stuff\n",
       "                window.messageIds[message.uid] = true;\n",
       "\n",
       "                if (message.fadeTo) {\n",
       "                    this.fadeTo(message);\n",
       "                } else {\n",
       "                    var plot = $('#' + message.graphId)[0].contentWindow;\n",
       "                    plot.postMessage(message, window.plotlyDomains[message.graphId]);\n",
       "                }\n",
       "            }\n",
       "\n",
       "            return GraphView.__super__.update.apply(this);\n",
       "        },\n",
       "\n",
       "        /**\n",
       "         * Wrapper for jquery's `fadeTo` function.\n",
       "         *\n",
       "         * @param message Contains the id we need to find the element.\n",
       "         */\n",
       "        fadeTo: function (message) {\n",
       "            var plot = $('#' + message.graphId);\n",
       "            plot.fadeTo(message.duration, message.opacity);\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Register the GraphView with the widget manager.\n",
       "    return {\n",
       "        GraphView: GraphView\n",
       "    }\n",
       "\n",
       "});\n",
       "\n",
       "//@ sourceURL=graphWidget.js\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cirrus\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import tools\n",
    "import plotly.tools as tls   \n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, clear_output\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.widgets import GraphWidget\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import random\n",
    "\n",
    "class mock():\n",
    "    \n",
    "    def __init__(self, strid):\n",
    "        self.pipe = py.Stream(strid)\n",
    "        self.pipe.open()\n",
    "        self.kill_sig = threading.Event()\n",
    "    \n",
    "    def start_thread(self):\n",
    "        \n",
    "        def num_producer():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not self.kill_sig.is_set():\n",
    "                time.sleep(0.5)\n",
    "                now_time = time.time()\n",
    "                integer = random.random()\n",
    "                self.pipe.write(dict(x = now_time - start_time, y = integer))\n",
    "        \n",
    "        self.thr = threading.Thread(target=num_producer)\n",
    "        self.thr.start()\n",
    "        \n",
    "    def kill(self):\n",
    "        print(\"Mock received kill command\")\n",
    "        self.kill_sig.set()\n",
    "        self.thr.join()\n",
    "        self.pipe.close()\n",
    "        print(\"Mock is dead\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression workload\n",
      "Starting CollaborativeFilteringTask\n",
      "Running Logistic Regression workload\n",
      "Starting CollaborativeFilteringTask\n"
     ]
    }
   ],
   "source": [
    "import collab\n",
    "\n",
    "\n",
    "\n",
    "data_bucket = 'cirrus-criteo-kaggle-19b-random'\n",
    "model = 'model_v1'\n",
    "\n",
    "lr_task = collab.CollaborativeFiltering(\n",
    "             # number of workers\n",
    "             n_workers = 5,\n",
    "             # number of parameter servers\n",
    "             n_ps = 2,\n",
    "             # worker size in MB\n",
    "             worker_size = 128,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01,\n",
    "             epsilon=0.0001,\n",
    "             progress_callback = print,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip_public='ec2-54-188-0-164.us-west-2.compute.amazonaws.com',\n",
    "             ps_ip_private='172.31.26.54',\n",
    "             # username of VM\n",
    "             ps_username='ubuntu',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=False,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(835,840)\n",
    "             )\n",
    "\n",
    "lr_task1 = collab.CollaborativeFiltering(\n",
    "             # number of workers\n",
    "             n_workers = 5,\n",
    "             # number of parameter servers\n",
    "             n_ps = 2,\n",
    "             # worker size in MB\n",
    "             worker_size = 128,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01,\n",
    "             epsilon=0.0001,\n",
    "             progress_callback = print,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip_public='ec2-54-188-0-164.us-west-2.compute.amazonaws.com',\n",
    "             ps_ip_private='172.31.26.54',\n",
    "             # username of VM\n",
    "             ps_username='ubuntu',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=False,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(835,840)\n",
    "             )\n",
    "\n",
    "\n",
    "#model, loss = lr_task.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://plot.ly/~andrewmzhang/16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f9783731ac42c6bf022ea5e7c05d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training loss: (13.4, 1.02701) current cost ($):  0.00140688203424\n",
      "Current training loss: (14.489, 1.02592) current cost ($):  0.00140692116191\n",
      "[{'y': 1.03671, 'x': 8.2733, 'pointNumber': 7, 'curveNumber': 1}]\n",
      "Error task has received kill signal\n",
      "Lambda launcher has received kill signal\n",
      "Everyone is dead\n",
      "[{'y': 1.03671, 'x': 8.2733, 'pointNumber': 7, 'curveNumber': 1}]\n",
      "Everyone is dead\n",
      "PS has 7 lambdas\n",
      "Current training loss: (15.531, 1.02467) current cost ($):  0.00153450784035\n",
      "Current training loss: (16.56, 1.02339) current cost ($):  0.0015347722826\n",
      "PS has 7 lambdas\n",
      "Current training loss: (17.628, 1.02224) current cost ($):  0.00166262873681\n",
      "Current training loss: (18.669, 1.02117) current cost ($):  0.00166269457766\n",
      "[{'y': 1.02701, 'x': 13.4, 'pointNumber': 12, 'curveNumber': 0}]\n",
      "Lambda launcher has received kill signal\n",
      "Error task has received kill signal\n",
      "Everyone is dead\n",
      "[{'y': 1.02701, 'x': 13.4, 'pointNumber': 12, 'curveNumber': 0}]\n",
      "Everyone is dead\n"
     ]
    }
   ],
   "source": [
    "stream_ids = tls.get_credentials_file()['stream_ids']\n",
    "\n",
    "# Get stream id from stream id list \n",
    "stream_id0 = stream_ids[0]\n",
    "stream_id1 = stream_ids[1]\n",
    "stream_id2 = stream_ids[2]\n",
    "stream_id3 = stream_ids[3]\n",
    "\n",
    "\n",
    "stream_0 = go.Stream(\n",
    "    token=stream_id0,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_1 = go.Stream(\n",
    "    token=stream_id1,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_2 = go.Stream(\n",
    "    token=stream_id2,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_3 = go.Stream(\n",
    "    token=stream_id3,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    mode='lines+markers',\n",
    "    stream=stream_0         # (!) embed stream id, 1 per trace\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    stream=stream_1\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    stream=stream_2\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    stream=stream_3\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n",
    "\n",
    "    \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "url = py.plot(fig, filename='multiple-subplots', auto_open=False)\n",
    "print(url)\n",
    "g = GraphWidget(url)\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_handler(widget, msg):\n",
    "    print(msg)\n",
    "    global lr_task\n",
    "    if msg[0]['curveNumber'] == 0:\n",
    "        lr_task.kill()\n",
    "    if msg[0]['curveNumber'] == 1:\n",
    "        lr_task1.kill()\n",
    "\n",
    "pipe0 = py.Stream(stream_id0)\n",
    "pipe0.open()\n",
    "\n",
    "pipe1 = py.Stream(stream_id1)\n",
    "pipe1.open()\n",
    "\n",
    "def progress_callback0(time_loss, cost, task):\n",
    "    global pipe0\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    pipe0.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "    \n",
    "def progress_callback1(time_loss, cost, task):\n",
    "    global pipe1\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    pipe1.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "\n",
    "\n",
    "lr_task.progress_callback = progress_callback0\n",
    "lr_task1.progress_callback = progress_callback1\n",
    "\n",
    "\n",
    "g.on_click(message_handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72939aba996e476492faf3e00ddae58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description=u'Halt!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Halt!\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    lr_task.kill()\n",
    "    lr_task1.kill()\n",
    "\n",
    "\n",
    "button.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's specific ip: ec2-54-188-0-164.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm\n",
      "Done waiting... Attempting to copy over binary\n",
      "Copied parameter server\n",
      "Defining configuration file\n",
      "\n",
      "input_path: /home/ec2-user/cirrus/examples/ml/tests/test_mf/nf_parsed \n",
      "input_type: csv \n",
      "minibatch_size: 20 \n",
      "s3_size: 10000 \n",
      "model_type: CollaborativeFiltering \n",
      "learning_rate: 0.010000 \n",
      "epsilon: 0.000100 \n",
      "normalize: 1 \n",
      "limit_samples: 50000000 \n",
      "use_bias: 1 \n",
      "num_users: 480189 \n",
      "num_items: 17770 \n",
      "train_set: 0-5 \n",
      "s3_bucket: cirrus-netflix-not-normalized\n",
      "\n",
      "Launching ps\n",
      "Launching parameter server\n",
      "('cmd:', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"nohup ./parameter_server --config config_cf.txt --nworkers 10000 --rank 1 &> ps_output &\"')\n",
      "Launching lambdas\n",
      "Starting error taskLambdas have been launched\n",
      "('cmd', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"./parameter_server --config config_cf.txt --nworkers 10 --rank 2 --ps_ip \"172.31.26.54\"\" > error_out &')\n",
      "\n",
      "User's specific ip: ec2-54-188-0-164.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm\n",
      "Cost Model\n",
      "Done waiting... Attempting to copy over binary\n",
      "Copied parameter server\n",
      "Defining configuration file\n",
      "\n",
      "input_path: /home/ec2-user/cirrus/examples/ml/tests/test_mf/nf_parsed \n",
      "input_type: csv \n",
      "minibatch_size: 20 \n",
      "s3_size: 10000 \n",
      "model_type: CollaborativeFiltering \n",
      "learning_rate: 0.010000 \n",
      "epsilon: 0.000100 \n",
      "normalize: 1 \n",
      "limit_samples: 50000000 \n",
      "use_bias: 1 \n",
      "num_users: 480189 \n",
      "num_items: 17770 \n",
      "train_set: 0-5 \n",
      "s3_bucket: cirrus-netflix-not-normalized\n",
      "\n",
      "Launching ps\n",
      "Launching parameter server\n",
      "('cmd:', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"nohup ./parameter_server --config config_cf.txt --nworkers 10000 --rank 1 &> ps_output &\"')\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "Launching lambdas\n",
      "Starting error taskLambdas have been launched\n",
      "('cmd', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"./parameter_server --config config_cf.txt --nworkers 10 --rank 2 --ps_ip \"172.31.26.54\"\" > error_out &')\n",
      "\n",
      "Cost Model\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "Current training loss: (1.1007, 1.08849) current cost ($):  0.000255263783582\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "Current training loss: (1.1007, 1.08849) current cost ($):  0.00063792821064\n",
      "Current training loss: (2.1373, 1.08849) current cost ($):  0.000638513986015\n",
      "Current training loss: (2.1373, 1.08849) current cost ($):  0.000383075822194\n",
      "Current training loss: (3.1467, 1.07046) current cost ($):  0.000383124841944\n",
      "PS has 5 lambdas\n",
      "Current training loss: (3.1467, 1.07046) current cost ($):  0.000766356369464\n",
      "Current training loss: (4.1651, 1.0663) current cost ($):  0.000766538316917\n",
      "Current training loss: (4.1651, 1.0663) current cost ($):  0.000510761163139\n",
      "Current training loss: (5.1927, 1.05731) current cost ($):  0.000511032929484\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (5.1927, 1.05731) current cost ($):  0.000894525434748\n",
      "Current training loss: (6.2218, 1.048) current cost ($):  0.000894892611821\n",
      "Current training loss: (6.2218, 1.048) current cost ($):  0.00063879441363\n",
      "Current training loss: (7.2414, 1.0413) current cost ($):  0.000638989565722\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (7.2414, 1.0413) current cost ($):  0.00102261809851\n",
      "Current training loss: (8.2733, 1.03671) current cost ($):  0.00102270024382\n",
      "Current training loss: (8.2733, 1.03671) current cost ($):  0.000766757629395\n",
      "Current training loss: (9.2969, 1.03418) current cost ($):  0.000766939212163\n",
      "PS has 7 lambdas\n",
      "Current training loss: (9.2969, 1.03418) current cost ($):  0.00115032439365\n",
      "Current training loss: (10.345, 1.03138) current cost ($):  0.00115065312684\n",
      "Current training loss: (10.345, 1.03138) current cost ($):  0.000894687005424\n",
      "Current training loss: (11.389, 1.02969) current cost ($):  0.000894841814232\n",
      "PS has 7 lambdas\n",
      "Current training loss: (11.389, 1.02969) current cost ($):  0.00127862985115\n",
      "Current training loss: (12.426, 1.02849) current cost ($):  0.00127923086732\n",
      "Current training loss: (12.426, 1.02849) current cost ($):  0.00102300846348\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "try:\n",
    "    lr_task.run()\n",
    "    lr_task1.run()\n",
    "except KeyboardInterrupt:\n",
    "    lr_task.kill()\n",
    "    lr_task1.kill()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock received kill command\n",
      "Mock is dead\n"
     ]
    }
   ],
   "source": [
    "mock_obj.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
